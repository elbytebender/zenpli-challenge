{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Zenpli challenge\n",
        "\n",
        "### Parte 1.3\n"
      ],
      "metadata": {
        "id": "8bjSqO8k-Dat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar Java, Spark, and Findspark\n",
        "El siguiente bloque de codigo instala Apache Spark 3.4.0, Java 8 y [Findspark](https://github.com/minrk/findspark), una librería que hace facil instalar Spark en ambientes express (Google Colab, etc)"
      ],
      "metadata": {
        "id": "qPx5KJyS-OvK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xze3LYDJ-Cr7"
      },
      "outputs": [],
      "source": [
        "!rm -rf spark-3.4.0-bin-hadoop3.tgz\n",
        "!rm -rf spark-3.4.0-bin-hadoop3\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Varuiables de entorno para findspark"
      ],
      "metadata": {
        "id": "TWRPiKb9-vSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\"\n",
        "os.environ[\"SPARK_VERSION\"] = \"3.4\""
      ],
      "metadata": {
        "id": "VLFug4z_-ylK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports\n"
      ],
      "metadata": {
        "id": "mZiKyZPQ-3uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "pCtcHkkY-4jM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf\n",
        "\n",
        "from pyspark.sql.types import (ArrayType, LongType, StringType, StructField, StructType, IntegerType, StringType, DateType, DoubleType, TimestampType)\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "bzNrPO07_Adt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "akBZDCuX_ME9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos la configuración de Spark y creamos la sesión"
      ],
      "metadata": {
        "id": "uvvcJ8WX_M86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf() \\\n",
        "    .setMaster('local[*]') \\\n",
        "    .set(\"spark.sql.parquet.datetimeRebaseModeInWrite\", \"CORRECTED\") \\\n",
        "    .set(\"spark.sql.parquet.mergeSchema\", \"true\") \\\n",
        "    .set(\"spark.sql.parquet.outputTimestampType\", \"TIMESTAMP_MICROS\") \\\n",
        "    .set(\"spark.sql.caseSensitive\", \"true\") \\\n",
        "    .set(\"spark.storage.memoryFraction\", 1) \\\n",
        "    .set(\"spark.executor.memory\", \"20g\") \\\n",
        "    .set(\"spark.driver.memory\", \"20g\") \\\n",
        "    .set(\"spark.cores.max\", 5) \\\n",
        "    .set(\"spark.executor.cores\", 5)"
      ],
      "metadata": {
        "id": "riBqSc0h_NG0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "# Local\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"zenpli-challenge-app\") \\\n",
        "    .config('spark.sql.session.timeZone', 'UTC') \\\n",
        "    .config(conf=conf) \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "Zfaz5ZiN_PH9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el esquema apropiado"
      ],
      "metadata": {
        "id": "wGp34iI0_bSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField(\"key_1\", StringType()),\n",
        "    StructField(\"date_2\", TimestampType()),\n",
        "    StructField(\"cont_3\", DoubleType()),\n",
        "    StructField(\"cont_4\", DoubleType()),\n",
        "    StructField(\"disc_5\", IntegerType()),\n",
        "    StructField(\"disc_6\", IntegerType()),\n",
        "    StructField(\"cat_7\", StringType()),\n",
        "    StructField(\"cat_8\", StringType()),\n",
        "    StructField(\"cont_9\", DoubleType()),\n",
        "    StructField(\"cont_10\", DoubleType())\n",
        "])"
      ],
      "metadata": {
        "id": "UbvAsEIq_bv0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos la variable apuntando al archivo local"
      ],
      "metadata": {
        "id": "sQME3NuzCj6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'file:///content/backend-dev-data-dataset.txt'"
      ],
      "metadata": {
        "id": "nb2RcEsLCf-6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutamos la lectura"
      ],
      "metadata": {
        "id": "zpprgdeOCxNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read \\\n",
        "        .schema(schema) \\\n",
        "        .option(\"header\",True) \\\n",
        "        .option(\"delimiter\",\",\") \\\n",
        "        .option(\"quote\", \"\\\"\") \\\n",
        "        .option(\"escape\", \"\\\"\") \\\n",
        "        .option(\"unescapedQuoteHandling\", \"STOP_AT_DELIMITER\") \\\n",
        "        .csv(data_path)"
      ],
      "metadata": {
        "id": "xfLW_qVB_eus"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos la cantidad de registros"
      ],
      "metadata": {
        "id": "LSoGda9ACwiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ_cZnO9_Wtq",
        "outputId": "d5f85501-afea-41af-a49a-77ec2db99ddd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16825"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos esquema"
      ],
      "metadata": {
        "id": "4v4T4MTwC3Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQWJ5yqP_W2S",
        "outputId": "e4036d8d-4de0-4efe-f77b-a43222993371"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- key_1: string (nullable = true)\n",
            " |-- date_2: timestamp (nullable = true)\n",
            " |-- cont_3: double (nullable = true)\n",
            " |-- cont_4: double (nullable = true)\n",
            " |-- disc_5: integer (nullable = true)\n",
            " |-- disc_6: integer (nullable = true)\n",
            " |-- cat_7: string (nullable = true)\n",
            " |-- cat_8: string (nullable = true)\n",
            " |-- cont_9: double (nullable = true)\n",
            " |-- cont_10: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos los primeros 10 registros"
      ],
      "metadata": {
        "id": "fGRkzCpzC5q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2COTteD_DPE8",
        "outputId": "1a7fb640-1569-4982-dd27-7fb156cbc05a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+-------+------+------+------+--------+---------+------+-------+\n",
            "|key_1 |date_2             |cont_3 |cont_4|disc_5|disc_6|cat_7   |cat_8    |cont_9|cont_10|\n",
            "+------+-------------------+-------+------+------+------+--------+---------+------+-------+\n",
            "|HC2030|2016-11-16 00:00:00|622.27 |-2.36 |2     |6     |frequent|happy    |0.24  |0.25   |\n",
            "|sP8147|2004-02-18 00:00:00|1056.16|59.93 |2     |8     |never   |happy    |1.94  |2.29   |\n",
            "|Cq3823|2007-03-25 00:00:00|210.73 |-93.94|1     |1     |never   |happy    |-0.11 |-0.1   |\n",
            "|Hw9428|2013-12-28 00:00:00|1116.48|80.58 |3     |10    |never   |surprised|1.27  |1.15   |\n",
            "|xZ0360|2003-08-25 00:00:00|1038.3 |12.37 |6     |17    |never   |happy    |1.76  |1.76   |\n",
            "|IK2721|2012-10-19 00:00:00|835.17 |16.3  |4     |11    |frequent|surprised|2.04  |2.3    |\n",
            "|iK8875|2005-02-04 00:00:00|769.02 |75.69 |3     |2     |never   |happy    |-1.53 |-1.56  |\n",
            "|qd0312|2014-11-17 00:00:00|273.11 |66.2  |1     |8     |frequent|surprised|2.67  |2.95   |\n",
            "|IO1104|2020-11-24 00:00:00|1844.21|-54.11|1     |11    |never   |surprised|-0.42 |-0.43  |\n",
            "|mb3668|2002-02-26 00:00:00|2369.77|165.12|2     |7     |never   |happy    |-1.11 |-1.15  |\n",
            "+------+-------------------+-------+------+------+------+--------+---------+------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Transformar una variable y agregarla al conjunto de datos. (Aplique la función x^3 + exp(y) sobre\n",
        "cualquier tupla de variables continuas);\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tLyO0HC0_qU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformed = df.withColumn(\"transform_step_3_1\", F.expr(\"pow(cont_3, 3) + exp(cont_4)\"))\n",
        "df_transformed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajc9TwsG_sKl",
        "outputId": "130bd568-9263-495f-b908-bb97d0964e5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+-------+------+------+------+--------+---------+------+-------+--------------------+\n",
            "| key_1|             date_2| cont_3|cont_4|disc_5|disc_6|   cat_7|    cat_8|cont_9|cont_10|  transform_step_3_1|\n",
            "+------+-------------------+-------+------+------+------+--------+---------+------+-------+--------------------+\n",
            "|HC2030|2016-11-16 00:00:00| 622.27| -2.36|     2|     6|frequent|    happy|  0.24|   0.25| 2.409553601855032E8|\n",
            "|sP8147|2004-02-18 00:00:00|1056.16| 59.93|     2|     8|   never|    happy|  1.94|   2.29|1.064800632551066...|\n",
            "|Cq3823|2007-03-25 00:00:00| 210.73|-93.94|     1|     1|   never|    happy| -0.11|   -0.1|   9357915.116016999|\n",
            "|Hw9428|2013-12-28 00:00:00|1116.48| 80.58|     3|    10|   never|surprised|  1.27|   1.15|9.895764508800898E34|\n",
            "|xZ0360|2003-08-25 00:00:00| 1038.3| 12.37|     6|    17|   never|    happy|  1.76|   1.76|1.1195924776322393E9|\n",
            "|IK2721|2012-10-19 00:00:00| 835.17|  16.3|     4|    11|frequent|surprised|  2.04|    2.3| 5.945335267006142E8|\n",
            "|iK8875|2005-02-04 00:00:00| 769.02| 75.69|     3|     2|   never|    happy| -1.53|  -1.56|7.443022558373575E32|\n",
            "|qd0312|2014-11-17 00:00:00| 273.11|  66.2|     1|     8|frequent|surprised|  2.67|   2.95|5.627230462530925E28|\n",
            "|IO1104|2020-11-24 00:00:00|1844.21|-54.11|     1|    11|   never|surprised| -0.42|  -0.43| 6.272362039650461E9|\n",
            "|mb3668|2002-02-26 00:00:00|2369.77|165.12|     2|     7|   never|    happy| -1.11|  -1.15|5.136944242984202E71|\n",
            "|Ch8767|2019-06-26 00:00:00| 259.95|-21.14|     4|     7|   never|    happy|  0.06|   0.05|1.7565861949874997E7|\n",
            "|MB6485|2009-08-05 00:00:00|2432.88| -9.38|     1|     9|frequent|    happy| -1.15|   null|1.439998582606395...|\n",
            "|ja8141|2019-11-16 00:00:00|  55.65| 17.73|     5|     9|   never|    happy| -1.77|  -1.49|5.0295817775353774E7|\n",
            "|eX8597|2004-06-27 00:00:00|  462.2|-15.62|     6|    12|frequent|    happy|  0.25|   0.24| 9.873924984800015E7|\n",
            "|JW7796|2013-02-15 00:00:00| 610.23| -49.3|     3|     8|frequent|    happy|  0.76|   0.67|2.2723784581916702E8|\n",
            "|FN1858|2013-03-28 00:00:00|  642.9| 65.56|     3|    12|   never|surprised|  1.63|   1.88|2.967195991236815...|\n",
            "|Rh1612|2005-09-12 00:00:00| 450.99| 63.42|     2|    15|frequent|surprised|  0.75|   0.76|3.491049785638198E27|\n",
            "|ST3432|2015-11-21 00:00:00| 725.54|-60.67|     2|     3|   never|surprised| -0.03|  -0.03| 3.819302718874639E8|\n",
            "|Su2885|2014-11-01 00:00:00|3578.42| 67.19|     5|    15|   never|surprised| -3.22|  -2.88|1.514419660461703...|\n",
            "|Vu2232|2002-08-27 00:00:00|2381.03|-18.63|     3|     6|   never|surprised| -2.08|  -2.06|1.349878257191873E10|\n",
            "+------+-------------------+-------+------+------+------+--------+---------+------+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.   Agregación - Conteo de registros únicos (sobre cualquier columna de valores categóricos)."
      ],
      "metadata": {
        "id": "GnDD0uk_BamE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_df = df.groupBy(\"cat_8\",\"cat_7\").agg(F.count(\"key_1\").alias(\"cnt_keys\")).orderBy(F.col(\"cnt_keys\").desc())\n",
        "grouped_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKF1VcAuEuqM",
        "outputId": "e214092d-e4c4-46a0-9ea7-1d3cc3eec960"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+\n",
            "|    cat_8|     cat_7|cnt_keys|\n",
            "+---------+----------+--------+\n",
            "|    happy|     never|    3958|\n",
            "|    happy|  frequent|    3856|\n",
            "|surprised|     never|    3505|\n",
            "|surprised|  frequent|    3453|\n",
            "|      sad|  frequent|     604|\n",
            "|      sad|     never|     560|\n",
            "|    happy|infrequent|     315|\n",
            "|surprised|infrequent|     256|\n",
            "|    happy|    always|     129|\n",
            "|surprised|    always|     118|\n",
            "|      sad|infrequent|      51|\n",
            "|      sad|    always|      17|\n",
            "|   scared|     never|       2|\n",
            "|   scared|  frequent|       1|\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo mismo pero con Spark SQL"
      ],
      "metadata": {
        "id": "Vz8HAYK-FhlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"data\")\n",
        "\n",
        "my_new_df = spark.sql(\"\"\"\n",
        "  select cat_8,\n",
        "         cat_7,\n",
        "         count(key_1) as cnt_keys\n",
        "  from data\n",
        "  group by 1, 2\n",
        "  order by 3 desc\n",
        "\"\"\")\n",
        "\n",
        "my_new_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgbuR5nHBa1t",
        "outputId": "9be983cd-067a-42ee-bd92-877604c72483"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+\n",
            "|    cat_8|     cat_7|cnt_keys|\n",
            "+---------+----------+--------+\n",
            "|    happy|     never|    3958|\n",
            "|    happy|  frequent|    3856|\n",
            "|surprised|     never|    3505|\n",
            "|surprised|  frequent|    3453|\n",
            "|      sad|  frequent|     604|\n",
            "|      sad|     never|     560|\n",
            "|    happy|infrequent|     315|\n",
            "|surprised|infrequent|     256|\n",
            "|    happy|    always|     129|\n",
            "|surprised|    always|     118|\n",
            "|      sad|infrequent|      51|\n",
            "|      sad|    always|      17|\n",
            "|   scared|     never|       2|\n",
            "|   scared|  frequent|       1|\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}